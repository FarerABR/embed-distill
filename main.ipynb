{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5470ab2",
   "metadata": {},
   "source": [
    "# Knowledge distillation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d0535",
   "metadata": {},
   "source": [
    "### installing dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce70383",
   "metadata": {},
   "source": [
    "### kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebfc2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410872111f684ceeabda37db564338f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "kagglehub.login()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c591ac",
   "metadata": {},
   "source": [
    "## 1. Imports and defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /win_d/Programming/embed-distill\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "VRAM: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import kagglehub\n",
    "from io import StringIO\n",
    "\n",
    "# ============================\n",
    "# CONFIG â€” change these values\n",
    "# ============================\n",
    "KAGGLE_USERNAME     = \"farerabr\"           # your Kaggle username\n",
    "TRAIN_DATASET       = \"persian-wikipedia-sentences\"  # Kaggle dataset name (e.g. \"farerabr/persian-wikipedia-sentences\")\n",
    "EMBEDDINGS_DATASET  = \"persian-sentence-embedded-jina-v3\"  # name for the output dataset with embeddings\n",
    "# ==============================\n",
    "\n",
    "# --- Config\n",
    "EPOCHS          = 30\n",
    "PATIENCE        = 5\n",
    "BATCH_SIZE      = 256\n",
    "LR_STUDENT  = 2e-5\n",
    "LR_PROJ     = 5e-3\n",
    "TEMPERATURE     = 0.05\n",
    "TEACHER_MODEL   = 'jinaai/jina-embeddings-v3'\n",
    "STUDENT_MODEL   = 'HooshvareLab/bert-fa-base-uncased'\n",
    "\n",
    "# --- Paths \n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "EMB_DIR  = os.path.join(BASE_DIR, 'embeddings')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "CHECKPOINT_DIR  = os.path.join(MODEL_DIR, 'checkpoints')\n",
    "\n",
    "for d in [DATA_DIR, EMB_DIR, MODEL_DIR, CHECKPOINT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "print(\"Base directory:\", BASE_DIR)\n",
    "\n",
    "# --- Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('No GPU found â€” make sure you are on Colab with GPU runtime for teacher inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d19f57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4942b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 batch files\n",
      "  Loaded persian_sentences_batch1.txt: 972,642 sentences\n",
      "  Loaded persian_sentences_batch2.txt: 979,907 sentences\n",
      "  Loaded persian_sentences_batch3.txt: 982,530 sentences\n",
      "  Loaded persian_sentences_batch4.txt: 966,101 sentences\n",
      "  Loaded persian_sentences_batch5.txt: 972,442 sentences\n",
      "\n",
      "Total sentences loaded: 4,873,622\n",
      "Train: 4,629,940\n",
      "Val:   243,682\n",
      "Saved train â†’ /win_d/Programming/embed-distill/data/train_sentences.txt (1017.3 MB)\n",
      "Saved val â†’ /win_d/Programming/embed-distill/data/val_sentences.txt (53.6 MB)\n"
     ]
    }
   ],
   "source": [
    "# Download dataset from Kaggle\n",
    "path = kagglehub.dataset_download(f\"{KAGGLE_USERNAME}/{TRAIN_DATASET}\")\n",
    "print(f'Dataset downloaded to: {path}')\n",
    "\n",
    "# Load all batch files\n",
    "all_sentences = []\n",
    "batch_files = sorted([f for f in os.listdir(DATA_DIR) if f.startswith('persian_sentences_batch')])\n",
    "print(f'Found {len(batch_files)} batch files')\n",
    "\n",
    "for batch_file in batch_files:\n",
    "    file_path = os.path.join(DATA_DIR, batch_file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    all_sentences.extend(sentences)\n",
    "    print(f'  Loaded {batch_file}: {len(sentences):,} sentences')\n",
    "\n",
    "print(f'\\nTotal sentences loaded: {len(all_sentences):,}')\n",
    "\n",
    "\n",
    "# --- Train/Val split (95/5)\n",
    "train_sentences, val_sentences = train_test_split(\n",
    "    all_sentences,\n",
    "    test_size=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_sentences):,}')\n",
    "print(f'Val:   {len(val_sentences):,}')\n",
    "\n",
    "# --- Save splits locally\n",
    "for name, split in [('train', train_sentences), ('val', val_sentences)]:\n",
    "    save_path = os.path.join(DATA_DIR, f'{name}_sentences.txt')\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(split))\n",
    "    size = os.path.getsize(save_path) / 1e6\n",
    "    print(f'Saved {name} â†’ {save_path} ({size:.1f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa4da1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Teacher embedding(jina-v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a17ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jina-v3 teacher model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde83c66fe42410c80b3a9d8ca50862e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher embedding dim: 1024\n",
      "Sentences to embed: 4,629,940\n",
      "Resuming from sentence 1,153,536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c000d99db7344f0ae23c2d13d097bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding:   0%|          | 0/13580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Config\n",
    "SAVE_EVERY = 50_000    # checkpoint every 50K (more efficient with large dataset)\n",
    "\n",
    "# --- Load teacher\n",
    "print(\"Loading Jina-v3 teacher model...\")\n",
    "teacher = SentenceTransformer(\n",
    "    TEACHER_MODEL,\n",
    "    device=device,\n",
    "    trust_remote_code=True,  # allow loading custom code from Hugging Face (required for Jina-v3)\n",
    ")\n",
    "\n",
    "print(f\"Teacher embedding dim: {teacher.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# --- Load train sentences\n",
    "with open(os.path.join(DATA_DIR, 'train_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    train_sentences = [l.strip() for l in f if l.strip()]\n",
    "print(f\"Sentences to embed: {len(train_sentences):,}\")\n",
    "\n",
    "# --- Resume support\n",
    "emb_path   = os.path.join(EMB_DIR, 'train_embeddings.npy')\n",
    "index_path = os.path.join(EMB_DIR, 'train_embedded_count.txt')\n",
    "\n",
    "if os.path.exists(index_path) and os.path.exists(emb_path):\n",
    "    with open(index_path) as f:\n",
    "        start_idx = int(f.read().strip())\n",
    "    embeddings = []  # start empty, existing data is in the file\n",
    "    print(f\"Resuming from sentence {start_idx:,}\")\n",
    "else:\n",
    "    start_idx  = 0\n",
    "    embeddings = []\n",
    "    print(\"Starting fresh\")\n",
    "\n",
    "# --- Generate embeddings\n",
    "torch.cuda.empty_cache()\n",
    "total_saved = start_idx  # track true total across all checkpoints\n",
    "teacher.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(start_idx, len(train_sentences), BATCH_SIZE), desc='Embedding'):\n",
    "        batch = train_sentences[i : i + BATCH_SIZE]\n",
    "        embs  = teacher.encode(\n",
    "            batch,\n",
    "            task='text-matching',\n",
    "            batch_size=BATCH_SIZE,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        embeddings.extend(embs)\n",
    "        total_saved += len(embs)\n",
    "\n",
    "        # Checkpoint\n",
    "        if len(embeddings) >= SAVE_EVERY:\n",
    "            chunk_idx = total_saved // SAVE_EVERY\n",
    "            chunk_path = os.path.join(EMB_DIR, f'train_embeddings_chunk{chunk_idx}.npy')\n",
    "            np.save(chunk_path, np.array(embeddings))\n",
    "            with open(index_path, 'w') as f:\n",
    "                f.write(str(total_saved))\n",
    "            print(f'Chunk {chunk_idx} saved: {total_saved:,}')\n",
    "\n",
    "            embeddings = []\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Save final remaining chunk\n",
    "if embeddings:\n",
    "    chunk_idx = (total_saved // SAVE_EVERY) + 1\n",
    "    chunk_path = os.path.join(EMB_DIR, f'train_embeddings_chunk{chunk_idx}.npy')\n",
    "    np.save(chunk_path, np.array(embeddings))\n",
    "    print(f'\\nâœ… Done! Total: {total_saved:,}')\n",
    "    \n",
    "# Val Embeddings\n",
    "with open(os.path.join(DATA_DIR, 'val_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    val_sentences = [l.strip() for l in f if l.strip()]\n",
    "print(f\"Val sentences to embed: {len(val_sentences):,}\")\n",
    "\n",
    "val_emb_path = os.path.join(EMB_DIR, 'val_embeddings.npy')\n",
    "\n",
    "val_embeddings = teacher.encode(\n",
    "    val_sentences,\n",
    "    task='text-matching',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "np.save(val_emb_path, val_embeddings)\n",
    "print(f\"\\nâœ… Done!\")\n",
    "print(f\"Val embeddings shape: {val_embeddings.shape}\")\n",
    "print(f\"Saved to: {val_emb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c9960-89a5-457d-a2ce-962ee98cadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge existing + new chunks\n",
    "import glob\n",
    "all_files = sorted(glob.glob(os.path.join(EMB_DIR, 'train_embeddings_chunk*.npy')))\n",
    "\n",
    "# Also include the original 150K file\n",
    "parts = [np.load(os.path.join(EMB_DIR, 'train_embeddings.npy'))]  # existing 150K\n",
    "parts += [np.load(f) for f in all_files]                           # new chunks\n",
    "\n",
    "final = np.concatenate(parts)\n",
    "np.save(os.path.join(EMB_DIR, 'train_embeddings_final.npy'), final)\n",
    "print(f'Final shape: {final.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2160463",
   "metadata": {},
   "source": [
    "### 3.1. Upload embeddings to kaggle\n",
    "\n",
    "This is not mandatory. Do as you please.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Uploading embeddings to Kaggle...\")\n",
    "kagglehub.dataset_upload(\n",
    "    handle=f\"{KAGGLE_USERNAME}/{EMBEDDINGS_DATASET}\",  # private dataset\n",
    "    local_dataset_dir=EMB_DIR,\n",
    ")\n",
    "print(\"âœ… Embeddings uploaded to Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69175103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding train sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4abb1da5aa4758bed1696bde00c533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding val sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf98a15a83c4e77a90a17a26a02ec9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings: (1000, 1024)\n",
      "Val embeddings:   (100, 1024)\n",
      "Saved âœ…\n"
     ]
    }
   ],
   "source": [
    "# Generate real teacher embeddings for sanity check (local 3050Ti)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load teacher\n",
    "teacher = SentenceTransformer(\n",
    "    TEACHER_MODEL, \n",
    "    trust_remote_code=True, \n",
    "    device=device,\n",
    "    )\n",
    "\n",
    "# Load sentences\n",
    "with open('./data/train_sentences.txt') as f:\n",
    "    test_train_sentences = [l.strip() for l in f if l.strip()][:1000]\n",
    "with open('./data/val_sentences.txt') as f:\n",
    "    test_val_sentences = [l.strip() for l in f if l.strip()][:100]\n",
    "\n",
    "# Embed train\n",
    "print(\"Embedding train sentences...\")\n",
    "test_train_embeddings = teacher.encode(\n",
    "    test_train_sentences,\n",
    "    task='text-matching',\n",
    "    batch_size=16,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Embed val\n",
    "print(\"Embedding val sentences...\")\n",
    "test_val_embeddings = teacher.encode(\n",
    "    test_val_sentences,\n",
    "    task='text-matching',\n",
    "    batch_size=16,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"Train embeddings: {test_train_embeddings.shape}\")\n",
    "print(f\"Val embeddings:   {test_val_embeddings.shape}\")\n",
    "\n",
    "np.save('./embeddings/train_embeddings_test.npy', test_train_embeddings)\n",
    "np.save('./embeddings/val_embeddings_test.npy', test_val_embeddings)\n",
    "print(\"Saved âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f4c9e",
   "metadata": {},
   "source": [
    "## Sanity Check -- remove before pushing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc7fb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.28.207.218"
     ]
    }
   ],
   "source": [
    "!curl ifconfig.me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac74e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SANITY CHECK â€” 1000 samples, 5 epochs, verify training works\n",
    "# ============================================================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp.grad_scaler import GradScaler\n",
    "from torch.amp.autocast_mode import autocast\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Config\n",
    "SANITY_EPOCHS   = 5\n",
    "SANITY_BATCH    = 16        # small for 3050Ti\n",
    "TEMPERATURE     = 0.05      # fixed from 4.0\n",
    "STUDENT_MODEL   = './bert-fa'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Load test data\n",
    "with open('./data/train_sentences.txt') as f:\n",
    "    sanity_train_sentences = [l.strip() for l in f if l.strip()][:1000]\n",
    "with open('./data/val_sentences.txt') as f:\n",
    "    sanity_val_sentences = [l.strip() for l in f if l.strip()][:100]\n",
    "\n",
    "sanity_train_emb = np.load('./embeddings/train_embeddings_test.npy')\n",
    "sanity_val_emb   = np.load('./embeddings/val_embeddings_test.npy')\n",
    "\n",
    "print(f\"Train: {len(sanity_train_sentences)} sentences, {sanity_train_emb.shape}\")\n",
    "print(f\"Val:   {len(sanity_val_sentences)} sentences, {sanity_val_emb.shape}\")\n",
    "\n",
    "# --- Dataset\n",
    "class DistillationDataset(Dataset):\n",
    "    def __init__(self, sentences, embeddings):\n",
    "        self.sentences  = sentences\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n",
    "        return self.sentences[idx], emb\n",
    "\n",
    "train_dataset = DistillationDataset(sanity_train_sentences, sanity_train_emb)\n",
    "val_dataset   = DistillationDataset(sanity_val_sentences,   sanity_val_emb)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=SANITY_BATCH, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=SANITY_BATCH, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "# --- Model\n",
    "tokenizer  = AutoTokenizer.from_pretrained(STUDENT_MODEL)\n",
    "student    = AutoModel.from_pretrained(STUDENT_MODEL).to(device)\n",
    "projection = nn.Linear(student.config.hidden_size, 1024).to(device)\n",
    "\n",
    "# --- Loss\n",
    "kl_criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "def distillation_loss(student_emb, teacher_emb, temperature=TEMPERATURE):\n",
    "    # 1. Direct cosine alignment loss (main signal)\n",
    "    cosine_loss = (1 - F.cosine_similarity(student_emb, teacher_emb, dim=-1)).mean()\n",
    "    \n",
    "    # 2. KL similarity matrix loss (relational structure)\n",
    "    student_sim = torch.mm(student_emb, student_emb.T) / temperature\n",
    "    teacher_sim = torch.mm(teacher_emb, teacher_emb.T) / temperature\n",
    "    kl = kl_criterion(\n",
    "        F.log_softmax(student_sim, dim=-1),\n",
    "        F.softmax(teacher_sim, dim=-1)\n",
    "    )\n",
    "    \n",
    "    # Combined loss\n",
    "    return cosine_loss + kl\n",
    "\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    return torch.sum(token_embeds * mask, dim=1) / torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "\n",
    "# --- Optimizer with separate LRs\n",
    "optimizer = AdamW([\n",
    "    {'params': student.parameters(),    'lr': 2e-5},\n",
    "    {'params': projection.parameters(), 'lr': 5e-3}\n",
    "], weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=SANITY_EPOCHS, eta_min=1e-6)\n",
    "scaler    = GradScaler()\n",
    "\n",
    "# --- Training loop\n",
    "for epoch in range(1, SANITY_EPOCHS + 1):\n",
    "\n",
    "    # Train\n",
    "    student.train()\n",
    "    projection.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for sentences, teacher_embs in tqdm(train_loader, desc=f'Epoch {epoch} Train'):\n",
    "        teacher_embs = teacher_embs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        encoded = tokenizer(\n",
    "            list(sentences),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            output      = student(**encoded)\n",
    "            student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "            student_emb = projection(student_emb)\n",
    "            student_emb = F.normalize(student_emb, dim=-1)\n",
    "            loss        = distillation_loss(student_emb, teacher_embs)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(projection.parameters()), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validate\n",
    "    student.eval()\n",
    "    projection.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentences, teacher_embs in tqdm(val_loader, desc=f'Epoch {epoch} Val'):\n",
    "            teacher_embs = teacher_embs.to(device)\n",
    "            encoded = tokenizer(\n",
    "                list(sentences),\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            with autocast(device_type='cuda'):\n",
    "                output      = student(**encoded)\n",
    "                student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "                student_emb = projection(student_emb)\n",
    "                student_emb = F.normalize(student_emb, dim=-1)\n",
    "                val_loss   += distillation_loss(student_emb, teacher_embs).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Train: {avg_train_loss:.4f} | Val: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- Check cosine similarity\n",
    "    student.eval()\n",
    "    projection.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_sentences = sanity_val_sentences[:50]\n",
    "        encoded = tokenizer(\n",
    "            sample_sentences,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        output      = student(**encoded)\n",
    "        student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "        student_emb = projection(student_emb)\n",
    "        student_emb = F.normalize(student_emb, dim=-1)\n",
    "        teacher_sample = torch.tensor(sanity_val_emb[:50], dtype=torch.float32).to(device)\n",
    "        cos_sim = F.cosine_similarity(student_emb, teacher_sample, dim=-1)\n",
    "        print(f\"  Cosine similarity: {cos_sim.mean():.4f} (target: >0.8)\")\n",
    "\n",
    "print(\"\\nâœ… Sanity check complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173991df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mean pool - mean: -0.0006, std: 0.6200\n",
      "After projection - mean: 0.0010, std: 0.6171\n",
      "After normalize - mean: 0.0001, std: 0.0313\n",
      "Teacher - mean: 0.0000, std: 0.0313\n",
      "Cosine sim per sample: tensor([0.6248, 0.6258, 0.6194, 0.4502, 0.6195, 0.6944, 0.5600, 0.5249, 0.6442,\n",
      "        0.5780], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check what the student is actually outputting\n",
    "student.eval()\n",
    "projection.eval()\n",
    "with torch.no_grad():\n",
    "    encoded = tokenizer(\n",
    "        sanity_val_sentences[:10],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    output      = student(**encoded)\n",
    "    student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "    print(f\"After mean pool - mean: {student_emb.mean():.4f}, std: {student_emb.std():.4f}\")\n",
    "    student_emb = projection(student_emb)\n",
    "    print(f\"After projection - mean: {student_emb.mean():.4f}, std: {student_emb.std():.4f}\")\n",
    "    student_emb = F.normalize(student_emb, dim=-1)\n",
    "    print(f\"After normalize - mean: {student_emb.mean():.4f}, std: {student_emb.std():.4f}\")\n",
    "    \n",
    "    teacher_sample = torch.tensor(sanity_val_emb[:10], dtype=torch.float32).to(device)\n",
    "    print(f\"Teacher - mean: {teacher_sample.mean():.4f}, std: {teacher_sample.std():.4f}\")\n",
    "    \n",
    "    cos_sim = F.cosine_similarity(student_emb, teacher_sample, dim=-1)\n",
    "    print(f\"Cosine sim per sample: {cos_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd45e55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Distillation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05538383",
   "metadata": {},
   "source": [
    "### 4.1. Loading data and Data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download embeddings from Kaggle\n",
    "path = kagglehub.dataset_download(f\"{KAGGLE_USERNAME}/{EMBEDDINGS_DATASET}\")\n",
    "print(f'Embeddings downloaded to: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading sentences...\")\n",
    "with open(os.path.join(DATA_DIR, 'train_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    train_sentences = [l.strip() for l in f if l.strip()]\n",
    "with open(os.path.join(DATA_DIR, 'val_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    val_sentences = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "print(\"Loading teacher embeddings...\")\n",
    "train_embeddings = np.load(os.path.join(EMB_DIR, 'train_embeddings.npy'))\n",
    "val_embeddings   = np.load(os.path.join(EMB_DIR, 'val_embeddings.npy'))\n",
    "\n",
    "print(f\"Train: {len(train_sentences):,} | Embeddings: {train_embeddings.shape}\")\n",
    "print(f\"Val:   {len(val_sentences):,} | Embeddings: {val_embeddings.shape}\")\n",
    "\n",
    "class DistillationDataset(Dataset):\n",
    "    def __init__(self, sentences, embeddings):\n",
    "        self.sentences  = sentences\n",
    "        self.embeddings = embeddings  # already loaded numpy array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n",
    "        return self.sentences[idx], emb  # no .copy() needed since it's in RAM\n",
    "\n",
    "train_dataset = DistillationDataset(train_sentences, train_embeddings)\n",
    "val_dataset   = DistillationDataset(val_sentences,   val_embeddings)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=16, pin_memory=True, prefetch_factor=4)\n",
    "val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True, prefetch_factor=4)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader):,}\")\n",
    "print(f\"Val batches:   {len(val_loader):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed4033",
   "metadata": {},
   "source": [
    "### 4.2. Loading student model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cde5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(token_embeds, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    return torch.sum(token_embeds * mask, dim=1) / torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "\n",
    "kl_criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "def distillation_loss(student_emb, teacher_emb, temperature=TEMPERATURE):\n",
    "    cosine_loss = (1 - F.cosine_similarity(student_emb, teacher_emb, dim=-1)).mean()\n",
    "    student_sim = torch.mm(student_emb, student_emb.T) / temperature\n",
    "    teacher_sim = torch.mm(teacher_emb, teacher_emb.T) / temperature\n",
    "    kl = kl_criterion(\n",
    "        F.log_softmax(student_sim, dim=-1),\n",
    "        F.softmax(teacher_sim, dim=-1)\n",
    "    )\n",
    "    return cosine_loss + kl\n",
    "\n",
    "print(f\"Loading student: {STUDENT_MODEL}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(STUDENT_MODEL)\n",
    "student   = AutoModel.from_pretrained(STUDENT_MODEL).to(device)\n",
    "\n",
    "student_dim = student.config.hidden_size\n",
    "teacher_dim = train_embeddings.shape[1]\n",
    "projection  = nn.Linear(student_dim, teacher_dim).to(device)\n",
    "\n",
    "print(f\"Student dim: {student_dim} â†’ Teacher dim: {teacher_dim}\")\n",
    "\n",
    "# --- Optimizer & Scheduler\n",
    "params    = list(student.parameters()) + list(projection.parameters())\n",
    "optimizer = AdamW([\n",
    "    {'params': student.parameters(),    'lr': LR_STUDENT},   # fine-tune BERT slowly\n",
    "    {'params': projection.parameters(), 'lr': LR_PROJ}    # train projection faster\n",
    "], weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5cdc0",
   "metadata": {},
   "source": [
    "### 4.3. Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "best_val_loss   = float('inf')\n",
    "patience_count  = 0\n",
    "start_epoch     = 1\n",
    "history         = {'train_loss': [], 'val_loss': []}\n",
    "best_model_path = os.path.join(MODEL_DIR, 'student_best.pt')\n",
    "\n",
    "# --- Resume from checkpoint if exists\n",
    "resume_path = os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pt')\n",
    "if os.path.exists(resume_path):\n",
    "    print(f\"Resuming from checkpoint...\")\n",
    "    ckpt = torch.load(resume_path, map_location=device)\n",
    "    student.load_state_dict(ckpt['student'])\n",
    "    projection.load_state_dict(ckpt['projection'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    scheduler.load_state_dict(ckpt['scheduler'])\n",
    "    start_epoch    = ckpt['epoch'] + 1\n",
    "    best_val_loss  = ckpt['best_val_loss']\n",
    "    patience_count = ckpt['patience_count']\n",
    "    history        = ckpt['history']\n",
    "    print(f\"Resumed from epoch {ckpt['epoch']} | Best val loss so far: {best_val_loss:.4f}\")\n",
    "else:\n",
    "    print(\"No checkpoint found, starting fresh\")\n",
    "\n",
    "# --- Training loop\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "\n",
    "    # Train\n",
    "    student.train()\n",
    "    projection.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for sentences, teacher_embs in tqdm(train_loader, desc=f'Epoch {epoch} Train'):\n",
    "        teacher_embs = teacher_embs.to(device)\n",
    "        encoded = tokenizer(\n",
    "            list(sentences),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=device):\n",
    "            output      = student(**encoded)\n",
    "            student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "            student_emb = projection(student_emb)\n",
    "            student_emb = F.normalize(student_emb, dim=-1)\n",
    "            loss        = distillation_loss(student_emb, teacher_embs)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validate\n",
    "    student.eval()\n",
    "    projection.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentences, teacher_embs in tqdm(val_loader, desc=f'Epoch {epoch} Val'):\n",
    "            teacher_embs = teacher_embs.to(device)\n",
    "            encoded = tokenizer(\n",
    "                list(sentences),\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            with autocast(device_type=device):\n",
    "                output      = student(**encoded)\n",
    "                student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "                student_emb = projection(student_emb)\n",
    "                student_emb = F.normalize(student_emb, dim=-1)\n",
    "                val_loss   += distillation_loss(student_emb, teacher_embs).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch:02d} | Train: {avg_train_loss:.4f} | Val: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss  = avg_val_loss\n",
    "        patience_count = 0\n",
    "        torch.save({\n",
    "            'student':    student.state_dict(),\n",
    "            'projection': projection.state_dict(),\n",
    "            'config': {\n",
    "                'student_model': STUDENT_MODEL,\n",
    "                'student_dim':   student_dim,\n",
    "                'teacher_dim':   teacher_dim,\n",
    "                'temperature':   TEMPERATURE,\n",
    "            }\n",
    "        }, best_model_path)\n",
    "        print(f\"  âœ… Best model saved (val loss: {best_val_loss:.4f})\")\n",
    "    else:\n",
    "        patience_count += 1\n",
    "        print(f\"  âš ï¸ No improvement ({patience_count}/{PATIENCE})\")\n",
    "        if patience_count >= PATIENCE:\n",
    "            print(f\"\\nğŸ›‘ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "    # --- Save latest checkpoint every epoch (for resume)\n",
    "    torch.save({\n",
    "        'epoch':          epoch,\n",
    "        'student':        student.state_dict(),\n",
    "        'projection':     projection.state_dict(),\n",
    "        'optimizer':      optimizer.state_dict(),\n",
    "        'scheduler':      scheduler.state_dict(),\n",
    "        'best_val_loss':  best_val_loss,\n",
    "        'patience_count': patience_count,\n",
    "        'history':        history,\n",
    "    }, resume_path)\n",
    "\n",
    "print(f\"\\nğŸ‰ Training complete! Best val loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b1030",
   "metadata": {},
   "source": [
    "### 4.4. Ploting training history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff963cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'],   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('KL Loss')\n",
    "plt.title('Distillation Training History')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d380bb3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490bba7",
   "metadata": {},
   "source": [
    "### 5.1. Loading farstail dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7232b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 1,564\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "n    535\n",
      "e    519\n",
      "c    510\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After binary conversion:\n",
      "  Positive pairs (entailment): 519\n",
      "  Negative pairs (neutral+contradiction): 1,045\n",
      "\n",
      "Sample pairs:\n",
      "\n",
      "  Premise:    Ø¯ÙˆØ±Ø§Ù† Ø§Ù…Ø§Ù…Øª Ø§Ù…Ø§Ù… ØµØ§Ø¯Ù‚ Ø¹Ù„ÛŒÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…ØŒ Ù…ØµØ§Ø¯Ù Ø§Ø³Øª Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø¢Ø«Ø§Ø± ÛŒÙˆÙ†Ø§Ù†ÛŒ Ùˆ Ú¯Ø³ØªØ±Ø´ Ù…Ø¨Ø§Ø±Ø²Ø§Øª ÙÚ©Ø±ÛŒ Ùˆ Ø§ÛŒØ¯Ø¦ÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ Ùˆ Ù†ÛŒØ² Ø¸Ù‡ÙˆØ± Ù…Ø°Ø§Ù‡Ø¨ Ùˆ Ù…Ú©ØªØ¨ Ù‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ.\n",
      "  Hypothesis: Ø§Ù…Ø§Ù… Ø³Ø¬Ø§Ø¯ (Ø¹) Ø¯Ø± Ø¯ÙˆØ±Ø§Ù†ÛŒ Ø§Ù…Ø§Ù…Øª Ú©Ø±Ø¯Ù†Ø¯ Ú©Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø¢Ø«Ø§Ø± ÛŒÙˆÙ†Ø§Ù†ÛŒØŒ Ø¸Ù‡ÙˆØ± Ù…Ø°Ø§Ù‡Ø¨ Ùˆ Ù…Ú©ØªØ¨ Ù‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ Ø¨ÙˆØ¯.\n",
      "  Label:      0 (unrelated)\n",
      "\n",
      "  Premise:    Ø¯ÙˆØ±Ø§Ù† Ø§Ù…Ø§Ù…Øª Ø§Ù…Ø§Ù… ØµØ§Ø¯Ù‚ Ø¹Ù„ÛŒÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…ØŒ Ù…ØµØ§Ø¯Ù Ø§Ø³Øª Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø¢Ø«Ø§Ø± ÛŒÙˆÙ†Ø§Ù†ÛŒ Ùˆ Ú¯Ø³ØªØ±Ø´ Ù…Ø¨Ø§Ø±Ø²Ø§Øª ÙÚ©Ø±ÛŒ Ùˆ Ø§ÛŒØ¯Ø¦ÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ Ùˆ Ù†ÛŒØ² Ø¸Ù‡ÙˆØ± Ù…Ø°Ø§Ù‡Ø¨ Ùˆ Ù…Ú©ØªØ¨ Ù‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ.\n",
      "  Hypothesis: Ø¯Ø³ØªÚ¯Ø§Ù‡ ÙØ§Ø³Ø¯ Ø­Ú©ÙˆÙ…ØªÛŒ Ø¨Ø§ ØµØ±Ù Ù‡Ø²ÛŒÙ†Ù‡ Ù‡Ø§ÛŒ Ù‡Ù†Ú¯ÙØªØŒ Ø³Ø¹ÛŒ Ø¯Ø± Ø¬Ø¹Ù„ Ø§Ø­Ø§Ø¯ÛŒØ« Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù†Ø­Ø±Ø§Ù Ø¯Ø± Ù…Ú©ØªØ¨ ØªØ´ÛŒØ¹ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª.\n",
      "  Label:      0 (unrelated)\n",
      "\n",
      "  Premise:    Ø¨Ø§ Ø´Ù‡Ø§Ø¯Øª Ø§Ù…Ø§Ù… Ø±Ø¶Ø§(Ø¹) Ù…Ø±Ø­Ù„Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² ØªÙ„Ø§Ø´ Ø§Ø¦Ù…Ù‡ Ø¢ØºØ§Ø² Ø´Ø¯ Ú©Ù‡ Â«Ø¯ÙˆØ±Ø§Ù† Ù…Ø­Ù†Øª Ø§Ù‡Ù„ Ø¨ÛŒØªÂ» Ù†Ø§Ù… Ø¯Ø§Ø±Ø¯.\n",
      "  Hypothesis: Ø¯ÙˆØ±Ø§Ù† Ù…Ø­Ù†Øª Ø§Ù‡Ù„ Ø¨ÛŒØª Ù¾Ø³ Ø§Ø² Ø´Ù‡Ø§Ø¯Øª Ø§Ù…Ø§Ù… Ø±Ø¶Ø§(Ø¹) Ø¢ØºØ§Ø² Ú¯Ø±Ø¯ÛŒØ¯.\n",
      "  Label:      1 (related)\n"
     ]
    }
   ],
   "source": [
    "# --- Load directly from GitHub\n",
    "url = 'https://raw.githubusercontent.com/dml-qom/FarsTail/master/data/Test-word.csv'\n",
    "response = requests.get(url)\n",
    "df = pd.read_csv(StringIO(response.text), sep='\\t')\n",
    "\n",
    "print(f\"Total test samples: {len(df):,}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# --- Convert to binary\n",
    "# e (entailment) â†’ 1, n (neutral) + c (contradiction) â†’ 0\n",
    "premise    = df['premise'].tolist()\n",
    "hypothesis = df['hypothesis'].tolist()\n",
    "labels     = [1 if l == 'e' else 0 for l in df['label']]\n",
    "\n",
    "print(f\"\\nAfter binary conversion:\")\n",
    "print(f\"  Positive pairs (entailment): {sum(labels):,}\")\n",
    "print(f\"  Negative pairs (neutral+contradiction): {len(labels)-sum(labels):,}\")\n",
    "\n",
    "# --- Sanity check\n",
    "print(\"\\nSample pairs:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n  Premise:    {premise[i]}\")\n",
    "    print(f\"  Hypothesis: {hypothesis[i]}\")\n",
    "    print(f\"  Label:      {labels[i]} ({'related' if labels[i]==1 else 'unrelated'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53a2eb",
   "metadata": {},
   "source": [
    "### 5.2. Evaluation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_st_model(model, premise, hypothesis, labels, batch_size=64, task=None):\n",
    "    \"\"\"Evaluate a SentenceTransformer model â€” returns AUC and scores.\"\"\"\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(premise), batch_size), desc='Evaluating'):\n",
    "            p_batch = premise[i : i + batch_size]\n",
    "            h_batch = hypothesis[i : i + batch_size]\n",
    "            kwargs  = dict(\n",
    "                batch_size=batch_size,\n",
    "                show_progress_bar=False,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            if task:\n",
    "                kwargs['task'] = task\n",
    "            p_embs = model.encode(p_batch, **kwargs)\n",
    "            h_embs = model.encode(h_batch, **kwargs)\n",
    "            scores.extend((p_embs * h_embs).sum(axis=1).tolist())\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    return auc, scores\n",
    "\n",
    "def evaluate_distilled_model(student, projection, tokenizer, premise, hypothesis, labels, batch_size=64):\n",
    "    \"\"\"Evaluate the distilled student model â€” returns AUC and scores.\"\"\"\n",
    "    student.eval()\n",
    "    projection.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(premise), batch_size), desc='Evaluating distilled'):\n",
    "            p_batch = premise[i : i + batch_size]\n",
    "            h_batch = hypothesis[i : i + batch_size]\n",
    "\n",
    "            def encode(sentences):\n",
    "                encoded = tokenizer(\n",
    "                    sentences,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors='pt'\n",
    "                ).to(device)\n",
    "                output = student(**encoded)\n",
    "                mask   = encoded['attention_mask']\n",
    "                emb    = (output.last_hidden_state * mask.unsqueeze(-1)).sum(1) / mask.sum(-1, keepdim=True)\n",
    "                emb    = projection(emb)\n",
    "                return F.normalize(emb, dim=-1).cpu().numpy()\n",
    "\n",
    "            p_embs = encode(list(p_batch))\n",
    "            h_embs = encode(list(h_batch))\n",
    "            scores.extend((p_embs * h_embs).sum(axis=1).tolist())\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    return auc, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c5180",
   "metadata": {},
   "source": [
    "### 5.3. Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Jina-v3 Teacher (Upper Bound)\n",
    "# ============================================================\n",
    "print(\"Loading Jina-v3 teacher...\")\n",
    "teacher = SentenceTransformer(TEACHER_MODEL, trust_remote_code=True, device=device)\n",
    "\n",
    "print(\"Evaluating Jina-v3 teacher...\")\n",
    "teacher_auc, teacher_scores = evaluate_st_model(\n",
    "    teacher, premise, hypothesis, labels, task='text-matching'\n",
    ")\n",
    "print(f\"âœ… Jina-v3 (Teacher) AUC-ROC: {teacher_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Raw bert-fa-base-uncased (Baseline, before distillation)\n",
    "# ============================================================\n",
    "print(\"Loading raw bert-fa-base-uncased...\")\n",
    "hakim_raw = SentenceTransformer(STUDENT_MODEL, device=device)\n",
    "\n",
    "print(\"Evaluating raw bert-fa-base-uncased...\")\n",
    "raw_auc, raw_scores = evaluate_st_model(\n",
    "    hakim_raw, premise, hypothesis, labels\n",
    ")\n",
    "print(f\"âœ… bert-fa-base-uncased (Raw baseline) AUC-ROC: {raw_auc:.4f}\")\n",
    "# ============================================================\n",
    "# Distilled bert-fa-base-uncased (Our result)\n",
    "# ============================================================\n",
    "print(\"Loading distilled student...\")\n",
    "tokenizer  = AutoTokenizer.from_pretrained(STUDENT_MODEL)\n",
    "student    = AutoModel.from_pretrained(STUDENT_MODEL).to(device)\n",
    "ckpt       = torch.load(os.path.join(MODEL_DIR, 'student_best.pt'), map_location=device)\n",
    "teacher_dim = ckpt['config']['teacher_dim']\n",
    "student_dim = ckpt['config']['student_dim']\n",
    "projection  = nn.Linear(student_dim, teacher_dim).to(device)\n",
    "\n",
    "ckpt = torch.load(os.path.join(MODEL_DIR, 'student_best.pt'), map_location=device)\n",
    "student.load_state_dict(ckpt['student'])\n",
    "projection.load_state_dict(ckpt['projection'])\n",
    "\n",
    "print(\"Evaluating distilled bert-fa-base-uncased...\")\n",
    "distilled_auc, distilled_scores = evaluate_distilled_model(\n",
    "    student, projection, tokenizer, premise, hypothesis, labels\n",
    ")\n",
    "print(f\"âœ… bert-fa-base-uncased (Distilled) AUC-ROC: {distilled_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade58cc9",
   "metadata": {},
   "source": [
    "### 5.4. Ploting the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a911260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Jina-v3   (Teacher, upper bound): {teacher_auc:.4f}\")\n",
    "print(f\"bert-fa-base-uncased (Raw baseline):        {raw_auc:.4f}\")\n",
    "print(f\"bert-fa-base-uncased (Distilled):           {distilled_auc:.4f}\")\n",
    "improvement = distilled_auc - raw_auc\n",
    "gap_closed  = improvement / (teacher_auc - raw_auc) * 100 if teacher_auc != raw_auc else 0\n",
    "print(f\"\\nImprovement over baseline: +{improvement:.4f}\")\n",
    "print(f\"Gap to teacher closed:      {gap_closed:.1f}%\")\n",
    "\n",
    "# --- Plot ROC curves\n",
    "plt.figure(figsize=(10, 7))\n",
    "for name, scores, auc in [\n",
    "    ('Jina-v3 Teacher',      teacher_scores,   teacher_auc),\n",
    "    ('bert-fa-base-uncased Raw',      raw_scores,       raw_auc),\n",
    "    ('bert-fa-base-uncased Distilled',distilled_scores, distilled_auc),\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random baseline')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves â€” FarsTail Persian STS Evaluation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'roc_curves.png'))\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPlot saved to: {os.path.join(MODEL_DIR, 'roc_curves.png')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
