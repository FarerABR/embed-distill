{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5470ab2",
   "metadata": {},
   "source": [
    "# Knowledge distillation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59618f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CONFIG â€” change these values\n",
    "# ============================\n",
    "KAGGLE_USERNAME     = \"farerabr\"           # your Kaggle username\n",
    "TRAIN_DATASET       = \"persian-wikipedia-sentences\"\n",
    "EMBEDDINGS_DATASET  = \"persian-distillation-embeddings-jina-v3\"\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d0535",
   "metadata": {},
   "source": [
    "### installing dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce70383",
   "metadata": {},
   "source": [
    "### kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebfc2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39092ca0fee24de8be705e7a0334f928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "kagglehub.login()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c591ac",
   "metadata": {},
   "source": [
    "## 1. Imports and defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /win_d/Programming/embed-distill\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "VRAM: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from hazm import SentenceTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# --- Config\n",
    "EPOCHS          = 30\n",
    "PATIENCE        = 5\n",
    "BATCH_SIZE      = 512\n",
    "LR              = 2e-5\n",
    "TEMPERATURE     = 4.0\n",
    "TEACHER_MODEL   = 'jinaai/jina-embeddings-v3'\n",
    "STUDENT_MODEL   = 'MCINext/Hakim-small'\n",
    "\n",
    "# --- Paths \n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "EMB_DIR  = os.path.join(BASE_DIR, 'embeddings')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "CHECKPOINT_DIR  = os.path.join(MODEL_DIR, 'checkpoints')\n",
    "\n",
    "for d in [DATA_DIR, EMB_DIR, MODEL_DIR, CHECKPOINT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "print(\"Base directory:\", BASE_DIR)\n",
    "\n",
    "# --- Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('No GPU found â€” make sure you are on Colab with GPU runtime for teacher inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d19f57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4942b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from Kaggle\n",
    "path = kagglehub.dataset_download(f\"{KAGGLE_USERNAME}/{TRAIN_DATASET}\", path=DATA_DIR)\n",
    "print(f'Dataset downloaded to: {path}')\n",
    "\n",
    "# Load all batch files\n",
    "all_sentences = []\n",
    "batch_files = sorted([f for f in os.listdir(path) if f.startswith('persian_sentences_batch')])\n",
    "print(f'Found {len(batch_files)} batch files')\n",
    "\n",
    "for batch_file in batch_files:\n",
    "    file_path = os.path.join(path, batch_file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    all_sentences.extend(sentences)\n",
    "    print(f'  Loaded {batch_file}: {len(sentences):,} sentences')\n",
    "\n",
    "print(f'\\nTotal sentences loaded: {len(all_sentences):,}')\n",
    "\n",
    "\n",
    "# --- Train/Val split (95/5)\n",
    "train_sentences, val_sentences = train_test_split(\n",
    "    all_sentences,\n",
    "    test_size=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_sentences):,}')\n",
    "print(f'Val:   {len(val_sentences):,}')\n",
    "\n",
    "# --- Save splits locally\n",
    "for name, split in [('train', train_sentences), ('val', val_sentences)]:\n",
    "    save_path = os.path.join(DATA_DIR, f'{name}_sentences.txt')\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(split))\n",
    "    size = os.path.getsize(save_path) / 1e6\n",
    "    print(f'Saved {name} â†’ {save_path} ({size:.1f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa4da1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Teacher embedding(jina-v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config\n",
    "BATCH_SIZE = 256       # lower this if the GPU is not good\n",
    "SAVE_EVERY = 50_000    # checkpoint every 50K (more efficient with large dataset)\n",
    "\n",
    "# --- Load teacher\n",
    "print(\"Loading Jina-v3 teacher model...\")\n",
    "teacher = SentenceTransformer(\n",
    "    TEACHER_MODEL,\n",
    "    device=device\n",
    ")\n",
    "print(f\"Teacher embedding dim: {teacher.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# --- Load train sentences\n",
    "with open(os.path.join(DATA_DIR, 'train_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    train_sentences = [l.strip() for l in f if l.strip()]\n",
    "print(f\"Sentences to embed: {len(train_sentences):,}\")\n",
    "\n",
    "# --- Resume support\n",
    "emb_path   = os.path.join(EMB_DIR, 'train_embeddings.npy')\n",
    "index_path = os.path.join(EMB_DIR, 'train_embedded_count.txt')\n",
    "\n",
    "if os.path.exists(index_path) and os.path.exists(emb_path):\n",
    "    with open(index_path) as f:\n",
    "        start_idx = int(f.read().strip())\n",
    "    embeddings = list(np.load(emb_path, mmap_mode='r'))  # memory map â†’ don't load all into RAM\n",
    "    print(f\"Resuming from sentence {start_idx:,}\")\n",
    "else:\n",
    "    start_idx  = 0\n",
    "    embeddings = []\n",
    "    print(\"Starting fresh\")\n",
    "\n",
    "# --- Generate embeddings\n",
    "teacher.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(start_idx, len(train_sentences), BATCH_SIZE), desc='Embedding'):\n",
    "        batch = train_sentences[i : i + BATCH_SIZE]\n",
    "        embs  = teacher.encode(\n",
    "            batch,\n",
    "            task='text-matching',\n",
    "            batch_size=BATCH_SIZE,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        embeddings.extend(embs)\n",
    "\n",
    "        # Checkpoint\n",
    "        if len(embeddings) % SAVE_EVERY == 0:\n",
    "            np.save(emb_path, np.array(embeddings))\n",
    "            with open(index_path, 'w') as f:\n",
    "                f.write(str(len(embeddings)))\n",
    "            print(f'  Checkpoint saved: {len(embeddings):,}')\n",
    "\n",
    "# --- Final save\n",
    "embeddings = np.array(embeddings)\n",
    "np.save(emb_path, embeddings)\n",
    "print(f\"\\nâœ… Done!\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Saved to: {emb_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2160463",
   "metadata": {},
   "source": [
    "### 3.1. Upload embeddings to kaggle\n",
    "\n",
    "This is not mandatory. Do as you please.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Uploading embeddings to Kaggle...\")\n",
    "kagglehub.dataset_upload(\n",
    "    handle=f\"{KAGGLE_USERNAME}/{EMBEDDINGS_DATASET}\",  # private dataset\n",
    "    local_dataset_dir=EMB_DIR,\n",
    ")\n",
    "print(\"âœ… Embeddings uploaded to Kaggle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd45e55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Distillation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05538383",
   "metadata": {},
   "source": [
    "## 4.1. Loading data and Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading sentences...\")\n",
    "with open(os.path.join(DATA_DIR, 'train_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    train_sentences = [l.strip() for l in f if l.strip()]\n",
    "with open(os.path.join(DATA_DIR, 'val_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    val_sentences = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "print(\"Loading teacher embeddings...\")\n",
    "train_embeddings = np.load(os.path.join(EMB_DIR, 'train_embeddings.npy'))\n",
    "val_embeddings   = np.load(os.path.join(EMB_DIR, 'val_embeddings.npy'))\n",
    "\n",
    "print(f\"Train: {len(train_sentences):,} | Embeddings: {train_embeddings.shape}\")\n",
    "print(f\"Val:   {len(val_sentences):,} | Embeddings: {val_embeddings.shape}\")\n",
    "\n",
    "class DistillationDataset(Dataset):\n",
    "    def __init__(self, sentences, embeddings):\n",
    "        self.sentences  = sentences\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.embeddings[idx]\n",
    "\n",
    "train_dataset = DistillationDataset(train_sentences, train_embeddings)\n",
    "val_dataset   = DistillationDataset(val_sentences,   val_embeddings)\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=8, pin_memory=True)\n",
    "val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader):,}\")\n",
    "print(f\"Val batches:   {len(val_loader):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed4033",
   "metadata": {},
   "source": [
    "## 4.2. Loading student model(hakim-small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cde5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(token_embeds, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    return torch.sum(token_embeds * mask, dim=1) / torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "\n",
    "def kl_loss(student_emb, teacher_emb, temperature=TEMPERATURE):\n",
    "    student_log_softmax = F.log_softmax(student_emb / temperature, dim=-1)\n",
    "    teacher_softmax     = F.softmax(teacher_emb   / temperature, dim=-1)\n",
    "    return F.kl_div(student_log_softmax, teacher_softmax, reduction='batchmean') * (temperature ** 2)\n",
    "\n",
    "print(f\"Loading student: {STUDENT_MODEL}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(STUDENT_MODEL)\n",
    "student   = AutoModel.from_pretrained(STUDENT_MODEL).to(device)\n",
    "\n",
    "student_dim = student.config.hidden_size\n",
    "teacher_dim = train_embeddings.shape[1]\n",
    "projection  = nn.Linear(student_dim, teacher_dim).to(device)\n",
    "\n",
    "print(f\"Student dim: {student_dim} â†’ Teacher dim: {teacher_dim}\")\n",
    "\n",
    "# --- Optimizer & Scheduler\n",
    "params    = list(student.parameters()) + list(projection.parameters())\n",
    "optimizer = AdamW(params, lr=LR, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5cdc0",
   "metadata": {},
   "source": [
    "## 4.3. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss   = float('inf')\n",
    "patience_count  = 0\n",
    "start_epoch     = 1\n",
    "history         = {'train_loss': [], 'val_loss': []}\n",
    "best_model_path = os.path.join(MODEL_DIR, 'student_best.pt')\n",
    "\n",
    "# --- Resume from checkpoint if exists\n",
    "resume_path = os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pt')\n",
    "if os.path.exists(resume_path):\n",
    "    print(f\"Resuming from checkpoint...\")\n",
    "    ckpt = torch.load(resume_path, map_location=device)\n",
    "    student.load_state_dict(ckpt['student'])\n",
    "    projection.load_state_dict(ckpt['projection'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    scheduler.load_state_dict(ckpt['scheduler'])\n",
    "    start_epoch    = ckpt['epoch'] + 1\n",
    "    best_val_loss  = ckpt['best_val_loss']\n",
    "    patience_count = ckpt['patience_count']\n",
    "    history        = ckpt['history']\n",
    "    print(f\"Resumed from epoch {ckpt['epoch']} | Best val loss so far: {best_val_loss:.4f}\")\n",
    "else:\n",
    "    print(\"No checkpoint found, starting fresh\")\n",
    "\n",
    "# --- Training loop\n",
    "for epoch in range(start_epoch, EPOCHS + 1):\n",
    "\n",
    "    # Train\n",
    "    student.train()\n",
    "    projection.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for sentences, teacher_embs in tqdm(train_loader, desc=f'Epoch {epoch} Train'):\n",
    "        teacher_embs = teacher_embs.to(device)\n",
    "        encoded = tokenizer(\n",
    "            list(sentences),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        output      = student(**encoded)\n",
    "        student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "        student_emb = projection(student_emb)\n",
    "        student_emb = F.normalize(student_emb, dim=-1)\n",
    "\n",
    "        loss = kl_loss(student_emb, teacher_embs)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validate\n",
    "    student.eval()\n",
    "    projection.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentences, teacher_embs in tqdm(val_loader, desc=f'Epoch {epoch} Val'):\n",
    "            teacher_embs = teacher_embs.to(device)\n",
    "            encoded = tokenizer(\n",
    "                list(sentences),\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            output      = student(**encoded)\n",
    "            student_emb = mean_pool(output.last_hidden_state, encoded['attention_mask'])\n",
    "            student_emb = projection(student_emb)\n",
    "            student_emb = F.normalize(student_emb, dim=-1)\n",
    "\n",
    "            val_loss += kl_loss(student_emb, teacher_embs).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch:02d} | Train: {avg_train_loss:.4f} | Val: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- Save latest checkpoint every epoch (for resume)\n",
    "    torch.save({\n",
    "        'epoch':          epoch,\n",
    "        'student':        student.state_dict(),\n",
    "        'projection':     projection.state_dict(),\n",
    "        'optimizer':      optimizer.state_dict(),\n",
    "        'scheduler':      scheduler.state_dict(),\n",
    "        'best_val_loss':  best_val_loss,\n",
    "        'patience_count': patience_count,\n",
    "        'history':        history,\n",
    "    }, resume_path)\n",
    "\n",
    "    # --- Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss  = avg_val_loss\n",
    "        patience_count = 0\n",
    "        torch.save({\n",
    "            'student':    student.state_dict(),\n",
    "            'projection': projection.state_dict(),\n",
    "            'config': {\n",
    "                'student_model': STUDENT_MODEL,\n",
    "                'student_dim':   student_dim,\n",
    "                'teacher_dim':   teacher_dim,\n",
    "                'temperature':   TEMPERATURE,\n",
    "            }\n",
    "        }, best_model_path)\n",
    "        print(f\"  âœ… Best model saved (val loss: {best_val_loss:.4f})\")\n",
    "    else:\n",
    "        patience_count += 1\n",
    "        print(f\"  âš ï¸ No improvement ({patience_count}/{PATIENCE})\")\n",
    "        if patience_count >= PATIENCE:\n",
    "            print(f\"\\nğŸ›‘ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nğŸ‰ Training complete! Best val loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b1030",
   "metadata": {},
   "source": [
    "## 4.4. Ploting training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff963cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'],   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('KL Loss')\n",
    "plt.title('Distillation Training History')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d380bb3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490bba7",
   "metadata": {},
   "source": [
    "## 5.1. Loading farstail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7232b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 1,564\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "n    535\n",
      "e    519\n",
      "c    510\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After binary conversion:\n",
      "  Positive pairs (entailment): 519\n",
      "  Negative pairs (neutral+contradiction): 1,045\n",
      "\n",
      "Sample pairs:\n",
      "\n",
      "  Premise:    Ø¯ÙˆØ±Ø§Ù† Ø§Ù…Ø§Ù…Øª Ø§Ù…Ø§Ù… ØµØ§Ø¯Ù‚ Ø¹Ù„ÛŒÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…ØŒ Ù…ØµØ§Ø¯Ù Ø§Ø³Øª Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø¢Ø«Ø§Ø± ÛŒÙˆÙ†Ø§Ù†ÛŒ Ùˆ Ú¯Ø³ØªØ±Ø´ Ù…Ø¨Ø§Ø±Ø²Ø§Øª ÙÚ©Ø±ÛŒ Ùˆ Ø§ÛŒØ¯Ø¦ÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ Ùˆ Ù†ÛŒØ² Ø¸Ù‡ÙˆØ± Ù…Ø°Ø§Ù‡Ø¨ Ùˆ Ù…Ú©ØªØ¨ Ù‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ.\n",
      "  Hypothesis: Ø§Ù…Ø§Ù… Ø³Ø¬Ø§Ø¯ (Ø¹) Ø¯Ø± Ø¯ÙˆØ±Ø§Ù†ÛŒ Ø§Ù…Ø§Ù…Øª Ú©Ø±Ø¯Ù†Ø¯ Ú©Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø¢Ø«Ø§Ø± ÛŒÙˆÙ†Ø§Ù†ÛŒØŒ Ø¸Ù‡ÙˆØ± Ù…Ø°Ø§Ù‡Ø¨ Ùˆ Ù…Ú©ØªØ¨ Ù‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ Ø¨ÙˆØ¯.\n",
      "  Label:      0 (unrelated)\n",
      "\n",
      "  Premise:    Ø¯ÙˆØ±Ø§Ù† Ø§Ù…Ø§Ù…Øª Ø§Ù…Ø§Ù… ØµØ§Ø¯Ù‚ Ø¹Ù„ÛŒÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…ØŒ Ù…ØµØ§Ø¯Ù Ø§Ø³Øª Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø¢Ø«Ø§Ø± ÛŒÙˆÙ†Ø§Ù†ÛŒ Ùˆ Ú¯Ø³ØªØ±Ø´ Ù…Ø¨Ø§Ø±Ø²Ø§Øª ÙÚ©Ø±ÛŒ Ùˆ Ø§ÛŒØ¯Ø¦ÙˆÙ„ÙˆÚ˜ÛŒÚ©ÛŒ Ùˆ Ù†ÛŒØ² Ø¸Ù‡ÙˆØ± Ù…Ø°Ø§Ù‡Ø¨ Ùˆ Ù…Ú©ØªØ¨ Ù‡Ø§ÛŒ Ø§Ù†Ø­Ø±Ø§ÙÛŒ.\n",
      "  Hypothesis: Ø¯Ø³ØªÚ¯Ø§Ù‡ ÙØ§Ø³Ø¯ Ø­Ú©ÙˆÙ…ØªÛŒ Ø¨Ø§ ØµØ±Ù Ù‡Ø²ÛŒÙ†Ù‡ Ù‡Ø§ÛŒ Ù‡Ù†Ú¯ÙØªØŒ Ø³Ø¹ÛŒ Ø¯Ø± Ø¬Ø¹Ù„ Ø§Ø­Ø§Ø¯ÛŒØ« Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù†Ø­Ø±Ø§Ù Ø¯Ø± Ù…Ú©ØªØ¨ ØªØ´ÛŒØ¹ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª.\n",
      "  Label:      0 (unrelated)\n",
      "\n",
      "  Premise:    Ø¨Ø§ Ø´Ù‡Ø§Ø¯Øª Ø§Ù…Ø§Ù… Ø±Ø¶Ø§(Ø¹) Ù…Ø±Ø­Ù„Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² ØªÙ„Ø§Ø´ Ø§Ø¦Ù…Ù‡ Ø¢ØºØ§Ø² Ø´Ø¯ Ú©Ù‡ Â«Ø¯ÙˆØ±Ø§Ù† Ù…Ø­Ù†Øª Ø§Ù‡Ù„ Ø¨ÛŒØªÂ» Ù†Ø§Ù… Ø¯Ø§Ø±Ø¯.\n",
      "  Hypothesis: Ø¯ÙˆØ±Ø§Ù† Ù…Ø­Ù†Øª Ø§Ù‡Ù„ Ø¨ÛŒØª Ù¾Ø³ Ø§Ø² Ø´Ù‡Ø§Ø¯Øª Ø§Ù…Ø§Ù… Ø±Ø¶Ø§(Ø¹) Ø¢ØºØ§Ø² Ú¯Ø±Ø¯ÛŒØ¯.\n",
      "  Label:      1 (related)\n"
     ]
    }
   ],
   "source": [
    "# --- Load directly from GitHub\n",
    "url = 'https://raw.githubusercontent.com/dml-qom/FarsTail/master/data/Test-word.csv'\n",
    "response = requests.get(url)\n",
    "df = pd.read_csv(StringIO(response.text), sep='\\t')\n",
    "\n",
    "print(f\"Total test samples: {len(df):,}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# --- Convert to binary\n",
    "# e (entailment) â†’ 1, n (neutral) + c (contradiction) â†’ 0\n",
    "premise    = df['premise'].tolist()\n",
    "hypothesis = df['hypothesis'].tolist()\n",
    "labels     = [1 if l == 'e' else 0 for l in df['label']]\n",
    "\n",
    "print(f\"\\nAfter binary conversion:\")\n",
    "print(f\"  Positive pairs (entailment): {sum(labels):,}\")\n",
    "print(f\"  Negative pairs (neutral+contradiction): {len(labels)-sum(labels):,}\")\n",
    "\n",
    "# --- Sanity check\n",
    "print(\"\\nSample pairs:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n  Premise:    {premise[i]}\")\n",
    "    print(f\"  Hypothesis: {hypothesis[i]}\")\n",
    "    print(f\"  Label:      {labels[i]} ({'related' if labels[i]==1 else 'unrelated'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53a2eb",
   "metadata": {},
   "source": [
    "## 5.2. Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_st_model(model, premise, hypothesis, labels, batch_size=64, task=None):\n",
    "    \"\"\"Evaluate a SentenceTransformer model â€” returns AUC and scores.\"\"\"\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(premise), batch_size), desc='Evaluating'):\n",
    "            p_batch = premise[i : i + batch_size]\n",
    "            h_batch = hypothesis[i : i + batch_size]\n",
    "            kwargs  = dict(\n",
    "                batch_size=batch_size,\n",
    "                show_progress_bar=False,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            if task:\n",
    "                kwargs['task'] = task\n",
    "            p_embs = model.encode(p_batch, **kwargs)\n",
    "            h_embs = model.encode(h_batch, **kwargs)\n",
    "            scores.extend((p_embs * h_embs).sum(axis=1).tolist())\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    return auc, scores\n",
    "\n",
    "def evaluate_distilled_model(student, projection, tokenizer, premise, hypothesis, labels, batch_size=64):\n",
    "    \"\"\"Evaluate the distilled student model â€” returns AUC and scores.\"\"\"\n",
    "    student.eval()\n",
    "    projection.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(premise), batch_size), desc='Evaluating distilled'):\n",
    "            p_batch = premise[i : i + batch_size]\n",
    "            h_batch = hypothesis[i : i + batch_size]\n",
    "\n",
    "            def encode(sentences):\n",
    "                encoded = tokenizer(\n",
    "                    sentences,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors='pt'\n",
    "                ).to(device)\n",
    "                output = student(**encoded)\n",
    "                mask   = encoded['attention_mask']\n",
    "                emb    = (output.last_hidden_state * mask.unsqueeze(-1)).sum(1) / mask.sum(-1, keepdim=True)\n",
    "                emb    = projection(emb)\n",
    "                return F.normalize(emb, dim=-1).cpu().numpy()\n",
    "\n",
    "            p_embs = encode(list(p_batch))\n",
    "            h_embs = encode(list(h_batch))\n",
    "            scores.extend((p_embs * h_embs).sum(axis=1).tolist())\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    return auc, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c5180",
   "metadata": {},
   "source": [
    "## 5.3. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Jina-v3 Teacher (Upper Bound)\n",
    "# ============================================================\n",
    "print(\"Loading Jina-v3 teacher...\")\n",
    "teacher = SentenceTransformer(TEACHER_MODEL, trust_remote_code=True, device=device)\n",
    "\n",
    "print(\"Evaluating Jina-v3 teacher...\")\n",
    "teacher_auc, teacher_scores = evaluate_st_model(\n",
    "    teacher, premise, hypothesis, labels, task='text-matching'\n",
    ")\n",
    "print(f\"âœ… Jina-v3 (Teacher) AUC-ROC: {teacher_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Raw Hakim-small (Baseline, before distillation)\n",
    "# ============================================================\n",
    "print(\"Loading raw Hakim-small...\")\n",
    "hakim_raw = SentenceTransformer(STUDENT_MODEL, device=device)\n",
    "\n",
    "print(\"Evaluating raw Hakim-small...\")\n",
    "raw_auc, raw_scores = evaluate_st_model(\n",
    "    hakim_raw, premise, hypothesis, labels\n",
    ")\n",
    "print(f\"âœ… Hakim-small (Raw baseline) AUC-ROC: {raw_auc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Distilled Hakim-small (Our result)\n",
    "# ============================================================\n",
    "print(\"Loading distilled student...\")\n",
    "tokenizer  = AutoTokenizer.from_pretrained(STUDENT_MODEL)\n",
    "student    = AutoModel.from_pretrained(STUDENT_MODEL).to(device)\n",
    "projection = nn.Linear(student.config.hidden_size, train_embeddings.shape[1]).to(device)\n",
    "\n",
    "ckpt = torch.load(os.path.join(MODEL_DIR, 'student_best.pt'), map_location=device)\n",
    "student.load_state_dict(ckpt['student'])\n",
    "projection.load_state_dict(ckpt['projection'])\n",
    "\n",
    "print(\"Evaluating distilled Hakim-small...\")\n",
    "distilled_auc, distilled_scores = evaluate_distilled_model(\n",
    "    student, projection, tokenizer, premise, hypothesis, labels\n",
    ")\n",
    "print(f\"âœ… Hakim-small (Distilled) AUC-ROC: {distilled_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade58cc9",
   "metadata": {},
   "source": [
    "## 5.4. Ploting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a911260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Jina-v3   (Teacher, upper bound): {teacher_auc:.4f}\")\n",
    "print(f\"Hakim-small (Raw baseline):        {raw_auc:.4f}\")\n",
    "print(f\"Hakim-small (Distilled):           {distilled_auc:.4f}\")\n",
    "improvement = distilled_auc - raw_auc\n",
    "gap_closed  = improvement / (teacher_auc - raw_auc) * 100 if teacher_auc != raw_auc else 0\n",
    "print(f\"\\nImprovement over baseline: +{improvement:.4f}\")\n",
    "print(f\"Gap to teacher closed:      {gap_closed:.1f}%\")\n",
    "\n",
    "# --- Plot ROC curves\n",
    "plt.figure(figsize=(10, 7))\n",
    "for name, scores, auc in [\n",
    "    ('Jina-v3 Teacher',      teacher_scores,   teacher_auc),\n",
    "    ('Hakim-small Raw',      raw_scores,       raw_auc),\n",
    "    ('Hakim-small Distilled',distilled_scores, distilled_auc),\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random baseline')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves â€” FarsTail Persian STS Evaluation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'roc_curves.png'))\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPlot saved to: {os.path.join(MODEL_DIR, 'roc_curves.png')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
