{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5470ab2",
   "metadata": {},
   "source": [
    "# Knowledge distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d0535",
   "metadata": {},
   "source": [
    "### installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets \\\n",
    "             transformers \\\n",
    "             torch \\\n",
    "             sentence-transformers \\\n",
    "             numpy \\\n",
    "             tqdm \\\n",
    "             scikit-learn \\\n",
    "             hazm \\\n",
    "             google.drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109226d1",
   "metadata": {},
   "source": [
    "### mounting google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18384c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive #type: ignore\n",
    "# Force unmount and remount with full access\n",
    "drive.flush_and_unmount()\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "!ls /content/drive/MyDrive/embed-distill/  # Check files in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c591ac",
   "metadata": {},
   "source": [
    "## 1. Imports and defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48e365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /content/drive/MyDrive/colab/embed-distill\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "VRAM: 15.6 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from hazm import SentenceTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.getipython import get_ipython\n",
    "\n",
    "# --- Paths \n",
    "BASE_DIR = '/content/drive/MyDrive/colab/embed-distill' if 'google.colab' in str(get_ipython()) else os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "EMB_DIR  = os.path.join(BASE_DIR, 'embeddings')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "for d in [DATA_DIR, EMB_DIR, MODEL_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "print(\"Base directory:\", BASE_DIR)\n",
    "\n",
    "# --- Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('No GPU found — make sure you are on Colab with GPU runtime for teacher inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d19f57",
   "metadata": {},
   "source": [
    "## 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90f64632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'wikimedia/wikipedia' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
      "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'wikimedia/wikipedia' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Persian Wikipedia (streaming)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5c58afcfb9434186d44ab2b1f30d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning articles: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final sentence count: 1,000,000\n",
      "Saved to /content/drive/MyDrive/colab/embed-distill/data/persian_sentences.txt\n",
      "Sample sentences:\n",
      "  → مقاله‌های برگزیده – مقالهٔ امروز بیشتر… امروز: ، میلادی برابر هجری خورشیدی و (UTC) → روز قبل – روز بعد ←یادبودهای – یادبودهای بیشتر… بایگانی – نگاره‌های برگزیدهٔ بیشتر\n",
      "  → ویکی‌پدیا یک دانشنامه برخط چندزبانه مبتنی بر وب با محتوای آزاد و همکاری باز است که با همکاری افراد داوطلب نوشته می‌شود و هر کسی که به اینترنت و وب دسترسی داشته باشد می‌تواند مقالات آن را ببیند و ویرایش کند.\n",
      "  → نام ویکی‌پدیا از پیوند واژه «ویکی» (به معنی وبگاه مشارکتی) با «پدیا» (گرفته‌شده از پسوند واژه encyclopedia به معنی دانشنامه یا دائرةالمعارف) ایجاد شده‌است.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Persian Wikipedia (streaming)...\")\n",
    "dataset = load_dataset(\n",
    "    'wikimedia/wikipedia',\n",
    "    '20231101.fa',\n",
    "    split='train',\n",
    "    streaming=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "sent_tokenizer = SentenceTokenizer()\n",
    "\n",
    "def clean_and_split(article_text):\n",
    "    \"\"\"Clean wiki markup and split into sentences.\"\"\"\n",
    "    # Remove wiki artifacts\n",
    "    text = re.sub(r'http\\S+', '', article_text)\n",
    "    text = re.sub(r'\\{\\{.*?\\}\\}', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\[\\[(?:[^|\\]]*\\|)?([^\\]]*)\\]\\]', r'\\1', text)\n",
    "    text = re.sub(r'[=\\*#\\|<>{}\\[\\]]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Split into sentences\n",
    "    sentences = sent_tokenizer.tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def is_valid(sentence):\n",
    "    \"\"\"Quality filter.\"\"\"\n",
    "    if len(sentence) < 20 or len(sentence) > 512:\n",
    "        return False\n",
    "    persian_ratio = len(re.findall(r'[\\u0600-\\u06FF]', sentence)) / len(sentence)\n",
    "    if persian_ratio < 0.4:           # at least 40% Persian characters\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# --- Extract sentences\n",
    "TARGET = 1_200_000   # collect a bit more than 1m to have buffer\n",
    "sentences = []\n",
    "\n",
    "for article in tqdm(dataset, desc='Scanning articles'):\n",
    "    sents = clean_and_split(article['text'])\n",
    "    sentences.extend([s for s in sents if is_valid(s)])\n",
    "    if len(sentences) >= TARGET:\n",
    "        break\n",
    "\n",
    "# Deduplicate\n",
    "sentences = list(dict.fromkeys(sentences))[:1_000_000]\n",
    "print(f'\\nFinal sentence count: {len(sentences):,}')\n",
    "\n",
    "# Save raw sentences\n",
    "sentences_path = os.path.join(DATA_DIR, 'persian_sentences.txt')\n",
    "with open(sentences_path, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(sentences))\n",
    "\n",
    "print(f'Saved to {sentences_path}')\n",
    "print(f'Sample sentences:')\n",
    "for s in sentences[:3]:\n",
    "    print(f'  → {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb97f0",
   "metadata": {},
   "source": [
    "## 3. Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ace5a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences loaded: 1,000,000\n",
      "Train: 950,000\n",
      "Val:   50,000\n",
      "Saved train split → /content/drive/MyDrive/colab/embed-distill/data/train_sentences.txt\n",
      "Saved val split → /content/drive/MyDrive/colab/embed-distill/data/val_sentences.txt\n"
     ]
    }
   ],
   "source": [
    "# Load saved sentences\n",
    "sentences_path = os.path.join(DATA_DIR, 'persian_sentences.txt')\n",
    "with open(sentences_path, 'r', encoding='utf-8') as f:\n",
    "    sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f'Total sentences loaded: {len(sentences):,}')\n",
    "\n",
    "# Train/Val split (95/5)\n",
    "train_sentences, val_sentences = train_test_split(\n",
    "    sentences,\n",
    "    test_size=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_sentences):,}')\n",
    "print(f'Val:   {len(val_sentences):,}')\n",
    "\n",
    "# Save splits\n",
    "for name, split in [('train', train_sentences), ('val', val_sentences)]:\n",
    "    path = os.path.join(DATA_DIR, f'{name}_sentences.txt')\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(split))\n",
    "    print(f'Saved {name} split → {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa4da1",
   "metadata": {},
   "source": [
    "## 4. Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a17ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jina-v3 teacher model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4375c9041ef438699eeea51fabc3c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/378 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581efdbe1e44ac0934d28aee5d2eeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/464 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d6aa68400f4d5bb7213dba54695221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c10063138b4136bba6175dd3cd757d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "custom_st.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-embeddings-v3:\n",
      "- custom_st.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9357be9d476e41e194ea6da798573661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4e36c1546d48bfbda812e7062044aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_xlm_roberta.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ee7de71f9641feb17d242f7a8c09b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_lora.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab5a684912542b9a7ce7611f052b28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_xlm_roberta.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b555b08ae25f481eaea3e2b2cad9f3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdf4c926e7d4808a853d950e7f44144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rotary.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044ad6304f334127bb4cb0a57497ea03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mha.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957204027d514aba83a89998043b7a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xlm_padding.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85e9751da284b5db766bfb3f872fa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89b45145ddb4a319ac5f4236339c9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stochastic_depth.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947fc9c4e92941c3add2e65b89a2a417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlp.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- stochastic_depth.py\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      "- embedding.py\n",
      "- rotary.py\n",
      "- mha.py\n",
      "- xlm_padding.py\n",
      "- block.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_lora.py\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65202e7d376e4999acada3b4b18efa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.cd915ad563445b5b8b51f4ac641e8c15e1fcbff3.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47d2ff47924426da833b6aa1ef2c653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f692b7363e4bb48d9dc30bdee08ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9346b521c56641a19c40ec80a28c2156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d877602cafb849b49e646f958fd5d0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/192 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher embedding dim: 1024\n",
      "Sentences to embed: 950,000\n",
      "Starting fresh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c701f5879eb543f1b3fff9162ab40549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding:   0%|          | 0/29688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mInvalid response: 404 Not Found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Config\n",
    "BATCH_SIZE = 64        # reduce to 16 if you get OOM\n",
    "SAVE_EVERY = 10_000    # checkpoint every 10K sentences\n",
    "\n",
    "# --- Load teacher\n",
    "print(\"Loading Jina-v3 teacher model...\")\n",
    "teacher = SentenceTransformer(\n",
    "    'jinaai/jina-embeddings-v3',\n",
    "    trust_remote_code=True,\n",
    "    device=device\n",
    ")\n",
    "print(f\"Teacher embedding dim: {teacher.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# --- Load train sentences\n",
    "with open(os.path.join(DATA_DIR, 'train_sentences.txt'), 'r', encoding='utf-8') as f:\n",
    "    train_sentences = [l.strip() for l in f if l.strip()]\n",
    "print(f\"Sentences to embed: {len(train_sentences):,}\")\n",
    "\n",
    "# --- Resume support: check how many already embedded\n",
    "emb_path    = os.path.join(EMB_DIR, 'train_embeddings.npy')\n",
    "index_path  = os.path.join(EMB_DIR, 'train_embedded_count.txt')\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    with open(index_path) as f:\n",
    "        start_idx = int(f.read().strip())\n",
    "    embeddings = list(np.load(emb_path))\n",
    "    print(f\"Resuming from sentence {start_idx:,}\")\n",
    "else:\n",
    "    start_idx  = 0\n",
    "    embeddings = []\n",
    "    print(\"Starting fresh\")\n",
    "\n",
    "# --- Generate embeddings in batches with checkpointing\n",
    "teacher.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(start_idx, len(train_sentences), BATCH_SIZE), desc='Embedding'):\n",
    "        batch = train_sentences[i : i + BATCH_SIZE]\n",
    "        embs  = teacher.encode(\n",
    "            batch,\n",
    "            task='text-matching',     # Jina-v3 is task-aware, this is correct task for STS\n",
    "            batch_size=BATCH_SIZE,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        embeddings.extend(embs)\n",
    "\n",
    "        # Checkpoint\n",
    "        if len(embeddings) % SAVE_EVERY == 0:\n",
    "            np.save(emb_path, np.array(embeddings))\n",
    "            with open(index_path, 'w') as f:\n",
    "                f.write(str(len(embeddings)))\n",
    "\n",
    "# --- Final save\n",
    "embeddings = np.array(embeddings)\n",
    "np.save(emb_path, embeddings)\n",
    "print(f\"\\n✅ Done!\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Saved to: {emb_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
